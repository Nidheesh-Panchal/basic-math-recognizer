{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport time\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-29T18:30:45.229823Z","iopub.execute_input":"2023-04-29T18:30:45.230525Z","iopub.status.idle":"2023-04-29T18:30:53.336974Z","shell.execute_reply.started":"2023-04-29T18:30:45.230489Z","shell.execute_reply":"2023-04-29T18:30:53.335896Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/handwritten-math-symbols/dataset\"\nos.listdir(data_dir)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:33:27.434350Z","iopub.execute_input":"2023-04-29T18:33:27.435589Z","iopub.status.idle":"2023-04-29T18:33:27.458270Z","shell.execute_reply.started":"2023-04-29T18:33:27.435549Z","shell.execute_reply":"2023-04-29T18:33:27.457230Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['7',\n '2',\n '5',\n 'div',\n '8',\n 'x',\n '0',\n 'y',\n 'z',\n 'add',\n '3',\n 'eq',\n 'dec',\n 'sub',\n '1',\n '4',\n '9',\n 'mul',\n '6',\n '.directory']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Setting batch size and the input image size","metadata":{}},{"cell_type":"code","source":"batch_size = 128\nimg_row = 28\nimg_col = 28\nchannel = 1","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:33:31.302381Z","iopub.execute_input":"2023-04-29T18:33:31.303300Z","iopub.status.idle":"2023-04-29T18:33:31.309371Z","shell.execute_reply.started":"2023-04-29T18:33:31.303247Z","shell.execute_reply":"2023-04-29T18:33:31.308228Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Setting labels for each folder names","metadata":{}},{"cell_type":"code","source":"labels = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'add': 10, 'dec': 11, 'div': 12, 'eq': 13, 'mul': 14, 'sub': 15, 'x':16, 'y': 17, 'z': 18, '[': 19, ']': 20}\nlabel = list(labels.keys())[:-2]\n\nnum_classes = len(label)\nprint(\"Labels dict: \", labels)\nprint(\"Labels list: \", label)\nprint(\"Num of classes: \", num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:33:33.633171Z","iopub.execute_input":"2023-04-29T18:33:33.633885Z","iopub.status.idle":"2023-04-29T18:33:33.642346Z","shell.execute_reply.started":"2023-04-29T18:33:33.633847Z","shell.execute_reply":"2023-04-29T18:33:33.640787Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Labels dict:  {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'add': 10, 'dec': 11, 'div': 12, 'eq': 13, 'mul': 14, 'sub': 15, 'x': 16, 'y': 17, 'z': 18, '[': 19, ']': 20}\nLabels list:  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'add', 'dec', 'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\nNum of classes:  19\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### A function that returns the image to be trained on. (reference to: ➗ Handwritten Equation Solver ➗)\nIt takes inverse of the image, uses threshold binary, take max contour from the image","metadata":{}},{"cell_type":"code","source":"# default take inverse, threshold binary, max contour\ndef get_image(file):\n    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n    img = ~img\n    _, thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    contour = sorted(contours, key = lambda ctr: cv2.boundingRect(ctr)[0])\n\n    a = int(28)\n    b = int(28)\n    maxi = 0\n    \n    for c in contour:\n        x,y,a,b=cv2.boundingRect(c)\n        \n        maxi=max(a*b,maxi)\n        if maxi==a*b:\n            x_max=x\n            y_max=y\n            w_max=a\n            h_max=b\n\n    im_crop = thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10]\n    im_resize = cv2.resize(im_crop,(28,28))\n#     cv2.rectangle(img, (x_max, y_max), (x_max + w_max, y_max + h_max), (0, 255, 0), 2)\n#     plt.imshow(img)\n    im_resize = np.reshape(im_resize,(784))\n    return im_resize","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:33:45.675496Z","iopub.execute_input":"2023-04-29T18:33:45.676241Z","iopub.status.idle":"2023-04-29T18:33:45.687072Z","shell.execute_reply.started":"2023-04-29T18:33:45.676203Z","shell.execute_reply":"2023-04-29T18:33:45.684045Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Take inverse of the image, threshold binary","metadata":{}},{"cell_type":"code","source":"# take inverse, threshold binary\ndef get_image_2(file):\n    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n    img = ~img\n    _, thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n\n    im_crop = thresh[:, :]\n    im_resize = cv2.resize(im_crop,(28,28))\n    im_resize = np.reshape(im_resize,(784))\n    return im_resize","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:33:46.429941Z","iopub.execute_input":"2023-04-29T18:33:46.430701Z","iopub.status.idle":"2023-04-29T18:33:46.438357Z","shell.execute_reply.started":"2023-04-29T18:33:46.430664Z","shell.execute_reply":"2023-04-29T18:33:46.437047Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Take inverse of the image, threshold zero","metadata":{}},{"cell_type":"code","source":"# take inverse, threshold tozero\ndef get_image_3(file):\n    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n    img = ~img\n    _, thresh = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n\n    im_crop = thresh[:, :]\n    im_resize = cv2.resize(im_crop,(28,28))\n    im_resize = np.reshape(im_resize,(784))\n    return im_resize","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:33:47.128192Z","iopub.execute_input":"2023-04-29T18:33:47.128768Z","iopub.status.idle":"2023-04-29T18:33:47.134882Z","shell.execute_reply.started":"2023-04-29T18:33:47.128732Z","shell.execute_reply":"2023-04-29T18:33:47.133763Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"take inverse of the image","metadata":{}},{"cell_type":"code","source":"# take inverse\ndef get_image_4(file):\n    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n    img = ~img\n    im_resize = cv2.resize(img,(28,28))\n    im_resize = np.reshape(im_resize,(784))\n    return im_resize","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:33:47.674828Z","iopub.execute_input":"2023-04-29T18:33:47.675613Z","iopub.status.idle":"2023-04-29T18:33:47.681427Z","shell.execute_reply.started":"2023-04-29T18:33:47.675560Z","shell.execute_reply":"2023-04-29T18:33:47.680051Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Modifying the reference code, take inverse of the image, threshold binary, merge all contours instead of taking just max, and make the contour close to square using threshold if not square","metadata":{}},{"cell_type":"code","source":"# modify the default, take inverse, threshold binary, merge all contours, make it square\ninc_thresh = 0.6\ndef get_image_5(file):\n    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n    img = ~img\n    _, thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    contour = sorted(contours, key = lambda ctr: cv2.boundingRect(ctr)[0])\n\n    a = int(28)\n    b = int(28)\n    x_max = np.Inf\n    y_max = np.Inf\n    w_max = 0\n    h_max = 0\n    \n    l,w = 0,0\n    \n    for c in contour:\n        x,y,a,b=cv2.boundingRect(c)\n        \n        x_max=min(x_max, x)\n        y_max=min(y_max, y)\n        w_max=max(x_max + w_max, x + a) - x_max\n        h_max=max(y_max + h_max, y + b) - y_max\n\n    add_x = 0\n    add_y = 0\n    if(w_max > h_max and h_max < inc_thresh * w_max):\n        add_y = round((inc_thresh * w_max - h_max) * inc_thresh)\n    if(h_max > w_max and w_max < inc_thresh * h_max):\n        add_x = round((inc_thresh * h_max - w_max) * inc_thresh)\n    \n    x = max(0, x_max - 5 - add_x)\n    y = max(0, y_max - 5 - add_y)\n    xa = min(len(img[0]), x_max + w_max + 5 + add_x)\n    yb = min(len(img), y_max + h_max + 5 + add_y)\n\n    im_crop = thresh[y:yb, x:xa]\n    im_resize = cv2.resize(im_crop,(28,28))\n#     cv2.rectangle(img, (x_max, y_max), (x_max + w_max, y_max + h_max), (0, 255, 0), 2)\n#     plt.imshow(img)\n    im_resize = np.reshape(im_resize,(784))\n    return im_resize","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:47:24.186676Z","iopub.execute_input":"2023-04-29T18:47:24.187070Z","iopub.status.idle":"2023-04-29T18:47:24.198538Z","shell.execute_reply.started":"2023-04-29T18:47:24.187034Z","shell.execute_reply":"2023-04-29T18:47:24.197468Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"Modifying the previous function, use threshold TOZERO","metadata":{}},{"cell_type":"code","source":"# modify the default, take inverse, threshold binary, merge all contours, make it square\ninc_thresh = 0.6\ndef get_image_6(file):\n    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n    img = ~img\n    _, thresh = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    contour = sorted(contours, key = lambda ctr: cv2.boundingRect(ctr)[0])\n\n    a = int(28)\n    b = int(28)\n    x_max = np.Inf\n    y_max = np.Inf\n    w_max = 0\n    h_max = 0\n    \n    l,w = 0,0\n    \n    for c in contour:\n        x,y,a,b=cv2.boundingRect(c)\n        \n        x_max=min(x_max, x)\n        y_max=min(y_max, y)\n        w_max=max(x_max + w_max, x + a) - x_max\n        h_max=max(y_max + h_max, y + b) - y_max\n\n    add_x = 0\n    add_y = 0\n    if(w_max > h_max and h_max < inc_thresh * w_max):\n        add_y = round((inc_thresh * w_max - h_max) * inc_thresh)\n    if(h_max > w_max and w_max < inc_thresh * h_max):\n        add_x = round((inc_thresh * h_max - w_max) * inc_thresh)\n    \n    x = max(0, x_max - 5 - add_x)\n    y = max(0, y_max - 5 - add_y)\n    xa = min(len(img[0]), x_max + w_max + 5 + add_x)\n    yb = min(len(img), y_max + h_max + 5 + add_y)\n\n    im_crop = thresh[y:yb, x:xa]\n    im_resize = cv2.resize(im_crop,(28,28))\n#     cv2.rectangle(img, (x_max, y_max), (x_max + w_max, y_max + h_max), (0, 255, 0), 2)\n#     plt.imshow(img)\n    im_resize = np.reshape(im_resize,(784))\n    return im_resize","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:46:54.568919Z","iopub.execute_input":"2023-04-29T18:46:54.569298Z","iopub.status.idle":"2023-04-29T18:46:54.581036Z","shell.execute_reply.started":"2023-04-29T18:46:54.569264Z","shell.execute_reply":"2023-04-29T18:46:54.580043Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Start picking up image files from each folder and label it","metadata":{}},{"cell_type":"code","source":"#create data\ndat = []\nfor folder in os.listdir(data_dir):\n    if(folder == \".directory\"):\n        continue\n    print(\"Label: \", folder)\n    cat = labels[folder]\n    for file in os.listdir(os.path.join(data_dir, folder)):\n        if(file == \".directory\"):\n            continue\n\n        row = get_image(os.path.join(data_dir, folder, file))\n        row = np.append(row, cat)\n        dat.append(row)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-29T18:54:08.727326Z","iopub.execute_input":"2023-04-29T18:54:08.727791Z","iopub.status.idle":"2023-04-29T18:54:23.411253Z","shell.execute_reply.started":"2023-04-29T18:54:08.727747Z","shell.execute_reply":"2023-04-29T18:54:23.410213Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Label:  7\nLabel:  2\nLabel:  5\nLabel:  div\nLabel:  8\nLabel:  x\nLabel:  0\nLabel:  y\nLabel:  z\nLabel:  add\nLabel:  3\nLabel:  eq\nLabel:  dec\nLabel:  sub\nLabel:  1\nLabel:  4\nLabel:  9\nLabel:  mul\nLabel:  6\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Create pandas dataframe and save it.","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(dat)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:54:26.303802Z","iopub.execute_input":"2023-04-29T18:54:26.304471Z","iopub.status.idle":"2023-04-29T18:54:29.457875Z","shell.execute_reply.started":"2023-04-29T18:54:26.304432Z","shell.execute_reply":"2023-04-29T18:54:29.456743Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"       0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n0        0    0    0    0    0  255  255  255  255  196  ...    0    0    0   \n1        0    0    0  255  255  255  255  255  255  235  ...    0    0    0   \n2      255  255  255  255  255  255  255  255  255  255  ...    0    0    0   \n3        0    0    0    9    9  255  255  255  255  255  ...    0    0    0   \n4        0    0   20   91   91  103  255  255  255  255  ...    0    0    0   \n...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n10066    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n10067    0    0    0    0    0    0   16  209  255    0  ...    0    0    0   \n10068    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n10069    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n10070    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n\n       778  779  780  781  782  783  784  \n0        0    0    0    0    0    0    7  \n1        0    0    0    0    0    0    7  \n2        0    0    0    0    0    0    7  \n3        0    0    0    0    0    0    7  \n4        0    0    0    0    0    0    7  \n...    ...  ...  ...  ...  ...  ...  ...  \n10066    0    0    0    0    0    0    6  \n10067    0    0    0    0    0    0    6  \n10068    0    0    0    0    0    0    6  \n10069    0    0    0    0    0    0    6  \n10070    0    0    0    0    0    0    6  \n\n[10071 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n      <th>784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>196</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>235</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>91</td>\n      <td>91</td>\n      <td>103</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>255</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10066</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10067</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n      <td>209</td>\n      <td>255</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10068</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10069</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10070</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>10071 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"suffix_index = 6\nsuffixes = [\"_norm\", \"_thresh_bin\", \"_thresh_zero\", \"_inv\", \"_merge_bin\", \"_merge_zero\"]\nsuffix = suffixes[suffix_index - 1]\n# suffix = \"_thresh_bin\"\n# suffix = \"_thresh_zero\"\n# suffix = \"_inv\"\n# suffix = \"_merge_bin\"\n# suffix = \"_merge_zero\"","metadata":{"execution":{"iopub.status.busy":"2023-04-29T19:10:04.983632Z","iopub.execute_input":"2023-04-29T19:10:04.984021Z","iopub.status.idle":"2023-04-29T19:10:04.990036Z","shell.execute_reply.started":"2023-04-29T19:10:04.983975Z","shell.execute_reply":"2023-04-29T19:10:04.988397Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"/kaggle/working/data\" + suffix + \".csv\")","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:54:33.568874Z","iopub.execute_input":"2023-04-29T18:54:33.569213Z","iopub.status.idle":"2023-04-29T18:54:34.676569Z","shell.execute_reply.started":"2023-04-29T18:54:33.569182Z","shell.execute_reply":"2023-04-29T18:54:34.675530Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"Read saved dataframe and prprocess it with normalization and one-hot encoding for labels","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/working/data\" + suffix + \".csv\", index_col=0)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T19:10:08.141567Z","iopub.execute_input":"2023-04-29T19:10:08.142475Z","iopub.status.idle":"2023-04-29T19:10:20.512866Z","shell.execute_reply.started":"2023-04-29T19:10:08.142406Z","shell.execute_reply":"2023-04-29T19:10:20.511814Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"X = df.values[:,:-1]\nY = df.values[:,-1]\n\nX = X.reshape(df.shape[0], img_row, img_col, channel).astype('float32')\nX = X / 255\nY = tf.keras.utils.to_categorical(Y, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T19:10:20.514819Z","iopub.execute_input":"2023-04-29T19:10:20.515203Z","iopub.status.idle":"2023-04-29T19:10:20.537474Z","shell.execute_reply.started":"2023-04-29T19:10:20.515165Z","shell.execute_reply":"2023-04-29T19:10:20.536541Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(Y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T18:55:01.622465Z","iopub.execute_input":"2023-04-29T18:55:01.622833Z","iopub.status.idle":"2023-04-29T18:55:01.628686Z","shell.execute_reply.started":"2023-04-29T18:55:01.622801Z","shell.execute_reply":"2023-04-29T18:55:01.627636Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"(10071, 28, 28, 1)\n(10071, 19)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Split the data into train and test","metadata":{}},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.15)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T19:10:20.538947Z","iopub.execute_input":"2023-04-29T19:10:20.539406Z","iopub.status.idle":"2023-04-29T19:10:20.605163Z","shell.execute_reply.started":"2023-04-29T19:10:20.539365Z","shell.execute_reply":"2023-04-29T19:10:20.603904Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_val.shape)\nprint(Y_val.shape)","metadata":{"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2023-04-29T18:55:11.739529Z","iopub.execute_input":"2023-04-29T18:55:11.739927Z","iopub.status.idle":"2023-04-29T18:55:11.746572Z","shell.execute_reply.started":"2023-04-29T18:55:11.739892Z","shell.execute_reply":"2023-04-29T18:55:11.745068Z"},"collapsed":true,"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"(8560, 28, 28, 1)\n(8560, 19)\n(1511, 28, 28, 1)\n(1511, 19)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model 1","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\n\n# model.add(tf.keras.layers.Rescaling(1./255))\nmodel.add(tf.keras.Input(shape=(img_row, img_col, channel))),\n\n#Adding data augmentation to the model\n# model.add(data_augment)\n# model.add(tf.keras.layers.RandomRotation(0.1)) # will have range of rotation [-1.6*2pi, 1.6*2pi] i.e. [10, 10] degrees\n# model.add(tf.keras.layers.RandomZoom(0.1)) # random zoom of +-10% takes same value for width as well to have the same aspect ratio\n# model.add(tf.keras.layers.RandomTranslation(0.1, 0.1))\n\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape = (img_row, img_col, channel), padding = \"same\"))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\n\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n# model.add(tf.keras.layers.Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n# model.add(tf.keras.layers.Dropout(0.2))\n\nmodel.add(tf.keras.layers.Flatten())\n\n# model.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))),\nmodel.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\nmodel.add(tf.keras.layers.Dense(50, activation='relu'))\nmodel.add(tf.keras.layers.Dense(num_classes, activation = \"softmax\"))\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.001,\n    decay_steps=1000,\n    decay_rate=0.9)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-04-29T19:10:29.728092Z","iopub.execute_input":"2023-04-29T19:10:29.728801Z","iopub.status.idle":"2023-04-29T19:10:29.819573Z","shell.execute_reply.started":"2023-04-29T19:10:29.728763Z","shell.execute_reply":"2023-04-29T19:10:29.818560Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nstart_time = time.time()\n# annealer = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nhistory = model.fit(X_train, Y_train, \n                    epochs=epochs,\n                    callbacks = [early_stop],\n#                     validation_split = 0.2,\n                    validation_data = (X_val, Y_val),\n                    verbose = 1)\n# history = model.fit(train_ds, \n#                     epochs=epochs,\n#                     callbacks = [early_stop],\n#                     validation_data=val_ds, # not trained on this data\n#                     verbose = 1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-29T19:10:32.996268Z","iopub.execute_input":"2023-04-29T19:10:32.996971Z","iopub.status.idle":"2023-04-29T19:12:13.762050Z","shell.execute_reply.started":"2023-04-29T19:10:32.996932Z","shell.execute_reply":"2023-04-29T19:12:13.761047Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2023-04-29 19:10:33.880453: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_10/dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"268/268 [==============================] - 4s 8ms/step - loss: 1.7495 - accuracy: 0.6829 - val_loss: 0.8115 - val_accuracy: 0.8948\nEpoch 2/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.6880 - accuracy: 0.9014 - val_loss: 0.5590 - val_accuracy: 0.9107\nEpoch 3/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.9350 - val_loss: 0.3862 - val_accuracy: 0.9451\nEpoch 4/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.3570 - accuracy: 0.9444 - val_loss: 0.3557 - val_accuracy: 0.9385\nEpoch 5/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.2943 - accuracy: 0.9492 - val_loss: 0.2766 - val_accuracy: 0.9550\nEpoch 6/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.2399 - accuracy: 0.9620 - val_loss: 0.2419 - val_accuracy: 0.9530\nEpoch 7/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.2169 - accuracy: 0.9607 - val_loss: 0.2113 - val_accuracy: 0.9583\nEpoch 8/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.2005 - accuracy: 0.9640 - val_loss: 0.2079 - val_accuracy: 0.9629\nEpoch 9/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1874 - accuracy: 0.9668 - val_loss: 0.1891 - val_accuracy: 0.9629\nEpoch 10/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1715 - accuracy: 0.9702 - val_loss: 0.2046 - val_accuracy: 0.9610\nEpoch 11/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1646 - accuracy: 0.9721 - val_loss: 0.1999 - val_accuracy: 0.9603\nEpoch 12/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1458 - accuracy: 0.9777 - val_loss: 0.1925 - val_accuracy: 0.9590\nEpoch 13/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.9748 - val_loss: 0.1905 - val_accuracy: 0.9669\nEpoch 14/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1395 - accuracy: 0.9770 - val_loss: 0.1636 - val_accuracy: 0.9709\nEpoch 15/100\n268/268 [==============================] - 1s 6ms/step - loss: 0.1229 - accuracy: 0.9810 - val_loss: 0.1506 - val_accuracy: 0.9735\nEpoch 16/100\n268/268 [==============================] - 2s 6ms/step - loss: 0.1243 - accuracy: 0.9792 - val_loss: 0.2133 - val_accuracy: 0.9550\nEpoch 17/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1229 - accuracy: 0.9775 - val_loss: 0.1752 - val_accuracy: 0.9669\nEpoch 18/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1135 - accuracy: 0.9820 - val_loss: 0.1568 - val_accuracy: 0.9669\nEpoch 19/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1017 - accuracy: 0.9838 - val_loss: 0.1782 - val_accuracy: 0.9682\nEpoch 20/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1006 - accuracy: 0.9841 - val_loss: 0.1654 - val_accuracy: 0.9616\nEpoch 21/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9821 - val_loss: 0.1450 - val_accuracy: 0.9715\nEpoch 22/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.9834 - val_loss: 0.1649 - val_accuracy: 0.9656\nEpoch 23/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0986 - accuracy: 0.9835 - val_loss: 0.1354 - val_accuracy: 0.9696\nEpoch 24/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0939 - accuracy: 0.9857 - val_loss: 0.1407 - val_accuracy: 0.9669\nEpoch 25/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0831 - accuracy: 0.9869 - val_loss: 0.1680 - val_accuracy: 0.9610\nEpoch 26/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0851 - accuracy: 0.9860 - val_loss: 0.1182 - val_accuracy: 0.9788\nEpoch 27/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0841 - accuracy: 0.9873 - val_loss: 0.1396 - val_accuracy: 0.9762\nEpoch 28/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0795 - accuracy: 0.9882 - val_loss: 0.1361 - val_accuracy: 0.9735\nEpoch 29/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9883 - val_loss: 0.1315 - val_accuracy: 0.9715\nEpoch 30/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0708 - accuracy: 0.9901 - val_loss: 0.1140 - val_accuracy: 0.9782\nEpoch 31/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0780 - accuracy: 0.9875 - val_loss: 0.1493 - val_accuracy: 0.9682\nEpoch 32/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9912 - val_loss: 0.1048 - val_accuracy: 0.9782\nEpoch 33/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0650 - accuracy: 0.9900 - val_loss: 0.1161 - val_accuracy: 0.9782\nEpoch 34/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9883 - val_loss: 0.1082 - val_accuracy: 0.9782\nEpoch 35/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0621 - accuracy: 0.9917 - val_loss: 0.1215 - val_accuracy: 0.9735\nEpoch 36/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0591 - accuracy: 0.9904 - val_loss: 0.1296 - val_accuracy: 0.9742\nEpoch 37/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 0.9919 - val_loss: 0.1098 - val_accuracy: 0.9782\nEpoch 38/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 0.9900 - val_loss: 0.1367 - val_accuracy: 0.9682\nEpoch 39/100\n268/268 [==============================] - 2s 6ms/step - loss: 0.0576 - accuracy: 0.9914 - val_loss: 0.1001 - val_accuracy: 0.9762\nEpoch 40/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0530 - accuracy: 0.9923 - val_loss: 0.1083 - val_accuracy: 0.9755\nEpoch 41/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0494 - accuracy: 0.9932 - val_loss: 0.0991 - val_accuracy: 0.9782\nEpoch 42/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0503 - accuracy: 0.9926 - val_loss: 0.0996 - val_accuracy: 0.9782\nEpoch 43/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0567 - accuracy: 0.9909 - val_loss: 0.1122 - val_accuracy: 0.9729\nEpoch 44/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0508 - accuracy: 0.9926 - val_loss: 0.0948 - val_accuracy: 0.9808\nEpoch 45/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0514 - accuracy: 0.9928 - val_loss: 0.1016 - val_accuracy: 0.9762\nEpoch 46/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0449 - accuracy: 0.9938 - val_loss: 0.1017 - val_accuracy: 0.9775\nEpoch 47/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0466 - accuracy: 0.9930 - val_loss: 0.0872 - val_accuracy: 0.9801\nEpoch 48/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0443 - accuracy: 0.9935 - val_loss: 0.0989 - val_accuracy: 0.9775\nEpoch 49/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0424 - accuracy: 0.9942 - val_loss: 0.0938 - val_accuracy: 0.9788\nEpoch 50/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0454 - accuracy: 0.9930 - val_loss: 0.0989 - val_accuracy: 0.9775\nEpoch 51/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0388 - accuracy: 0.9949 - val_loss: 0.0880 - val_accuracy: 0.9821\nEpoch 52/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0408 - accuracy: 0.9938 - val_loss: 0.0957 - val_accuracy: 0.9749\nEpoch 53/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0423 - accuracy: 0.9938 - val_loss: 0.0825 - val_accuracy: 0.9795\nEpoch 54/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9963 - val_loss: 0.0962 - val_accuracy: 0.9762\nEpoch 55/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0368 - accuracy: 0.9940 - val_loss: 0.0886 - val_accuracy: 0.9775\nEpoch 56/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0353 - accuracy: 0.9947 - val_loss: 0.0863 - val_accuracy: 0.9775\nEpoch 57/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.9961 - val_loss: 0.0850 - val_accuracy: 0.9782\nEpoch 58/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9953 - val_loss: 0.0931 - val_accuracy: 0.9788\nEpoch 59/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9949 - val_loss: 0.0937 - val_accuracy: 0.9749\nEpoch 60/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0356 - accuracy: 0.9946 - val_loss: 0.0930 - val_accuracy: 0.9762\nEpoch 61/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9956 - val_loss: 0.0965 - val_accuracy: 0.9762\nEpoch 62/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0349 - accuracy: 0.9950 - val_loss: 0.0840 - val_accuracy: 0.9775\nEpoch 63/100\n268/268 [==============================] - 2s 7ms/step - loss: 0.0315 - accuracy: 0.9954 - val_loss: 0.0688 - val_accuracy: 0.9828\nEpoch 64/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0320 - accuracy: 0.9950 - val_loss: 0.0803 - val_accuracy: 0.9801\nEpoch 65/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0302 - accuracy: 0.9966 - val_loss: 0.0758 - val_accuracy: 0.9815\nEpoch 66/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0269 - accuracy: 0.9964 - val_loss: 0.0851 - val_accuracy: 0.9768\nEpoch 67/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0283 - accuracy: 0.9959 - val_loss: 0.0801 - val_accuracy: 0.9815\nEpoch 68/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0286 - accuracy: 0.9958 - val_loss: 0.0852 - val_accuracy: 0.9788\nEpoch 69/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0270 - accuracy: 0.9965 - val_loss: 0.0798 - val_accuracy: 0.9828\nEpoch 70/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9966 - val_loss: 0.0756 - val_accuracy: 0.9821\nEpoch 71/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0252 - accuracy: 0.9968 - val_loss: 0.0791 - val_accuracy: 0.9795\nEpoch 72/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.0759 - val_accuracy: 0.9801\nEpoch 73/100\n268/268 [==============================] - 1s 5ms/step - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.0875 - val_accuracy: 0.9821\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"/kaggle/working/model_1\" + suffix + \".h5\")\nmodel.save_weights(\"/kaggle/working/model_1_weights\" + suffix + \".h5\")","metadata":{"execution":{"iopub.status.busy":"2023-04-29T19:12:13.764012Z","iopub.execute_input":"2023-04-29T19:12:13.764370Z","iopub.status.idle":"2023-04-29T19:12:13.817625Z","shell.execute_reply.started":"2023-04-29T19:12:13.764324Z","shell.execute_reply":"2023-04-29T19:12:13.816644Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"## Model 2\n\nIts just trained on all the data","metadata":{}},{"cell_type":"code","source":"model_2 = tf.keras.models.Sequential()\n\n# model.add(tf.keras.layers.Rescaling(1./255))\nmodel_2.add(tf.keras.Input(shape=(img_row, img_col, channel))),\n\n#Adding data augmentation to the model\n# model.add(data_augment)\n# model.add(tf.keras.layers.RandomRotation(0.1)) # will have range of rotation [-1.6*2pi, 1.6*2pi] i.e. [10, 10] degrees\n# model.add(tf.keras.layers.RandomZoom(0.1)) # random zoom of +-10% takes same value for width as well to have the same aspect ratio\n# model.add(tf.keras.layers.RandomTranslation(0.1, 0.1))\n\nmodel_2.add(tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape = (img_row, img_col, channel), padding = \"same\"))\nmodel_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel_2.add(tf.keras.layers.Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel_2.add(tf.keras.layers.Dropout(0.2))\n\nmodel_2.add(tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'))\nmodel_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n# model.add(tf.keras.layers.Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n# model.add(tf.keras.layers.Dropout(0.2))\n\nmodel_2.add(tf.keras.layers.Flatten())\n\n# model.add(tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))),\nmodel_2.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\nmodel_2.add(tf.keras.layers.Dense(50, activation='relu'))\nmodel_2.add(tf.keras.layers.Dense(num_classes, activation = \"softmax\"))\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.001,\n    decay_steps=1000,\n    decay_rate=0.9)\n\nmodel_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-04-29T19:12:19.548769Z","iopub.execute_input":"2023-04-29T19:12:19.549486Z","iopub.status.idle":"2023-04-29T19:12:19.641600Z","shell.execute_reply.started":"2023-04-29T19:12:19.549442Z","shell.execute_reply":"2023-04-29T19:12:19.640644Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nstart_time = time.time()\n# annealer = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nhistory = model_2.fit(X, Y, \n                    epochs=epochs,\n                    callbacks = [early_stop],\n                    validation_split = 0.2,\n                    verbose = 1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-29T19:12:20.224429Z","iopub.execute_input":"2023-04-29T19:12:20.224804Z","iopub.status.idle":"2023-04-29T19:12:37.334522Z","shell.execute_reply.started":"2023-04-29T19:12:20.224769Z","shell.execute_reply":"2023-04-29T19:12:37.333491Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2023-04-29 19:12:21.151537: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_11/dropout_11/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"252/252 [==============================] - 3s 6ms/step - loss: 1.6278 - accuracy: 0.7088 - val_loss: 13.0623 - val_accuracy: 0.1400\nEpoch 2/100\n252/252 [==============================] - 1s 5ms/step - loss: 0.6423 - accuracy: 0.9080 - val_loss: 15.4355 - val_accuracy: 0.1380\nEpoch 3/100\n252/252 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.9271 - val_loss: 14.5036 - val_accuracy: 0.1385\nEpoch 4/100\n252/252 [==============================] - 1s 6ms/step - loss: 0.3448 - accuracy: 0.9440 - val_loss: 17.4031 - val_accuracy: 0.1375\nEpoch 5/100\n252/252 [==============================] - 1s 6ms/step - loss: 0.2759 - accuracy: 0.9542 - val_loss: 16.8756 - val_accuracy: 0.1494\nEpoch 6/100\n252/252 [==============================] - 1s 5ms/step - loss: 0.2327 - accuracy: 0.9614 - val_loss: 17.2157 - val_accuracy: 0.1325\nEpoch 7/100\n252/252 [==============================] - 2s 7ms/step - loss: 0.2067 - accuracy: 0.9633 - val_loss: 15.7687 - val_accuracy: 0.1459\nEpoch 8/100\n252/252 [==============================] - 1s 5ms/step - loss: 0.1805 - accuracy: 0.9696 - val_loss: 16.8973 - val_accuracy: 0.1444\nEpoch 9/100\n252/252 [==============================] - 1s 5ms/step - loss: 0.1701 - accuracy: 0.9681 - val_loss: 18.7753 - val_accuracy: 0.1459\nEpoch 10/100\n252/252 [==============================] - 1s 6ms/step - loss: 0.1618 - accuracy: 0.9702 - val_loss: 20.7862 - val_accuracy: 0.1414\nEpoch 11/100\n252/252 [==============================] - 1s 5ms/step - loss: 0.1498 - accuracy: 0.9733 - val_loss: 18.5404 - val_accuracy: 0.1459\n","output_type":"stream"}]},{"cell_type":"code","source":"model_2.save(\"/kaggle/working/model_2\" + suffix + \".h5\")\nmodel_2.save_weights(\"/kaggle/working/model_2_weights\" + suffix + \".h5\")","metadata":{"execution":{"iopub.status.busy":"2023-04-29T19:12:37.336489Z","iopub.execute_input":"2023-04-29T19:12:37.336846Z","iopub.status.idle":"2023-04-29T19:12:37.389778Z","shell.execute_reply.started":"2023-04-29T19:12:37.336804Z","shell.execute_reply":"2023-04-29T19:12:37.388869Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_val,Y_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2.evaluate(X_val, Y_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotplot(history):\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    plot = plt.figure(figsize=(15,10))\n    plt.subplot(2, 2, 1)\n    plt.plot(accuracy, label = \"Training accuracy\")\n    plt.plot(val_accuracy, label=\"Validation accuracy\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"Accuracy vs Epochs\")\n\n    plt.subplot(2,2,2)\n    plt.plot(loss, label = \"Training loss\")\n    plt.plot(val_loss, label=\"Validation loss\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Loss vs epochs\")\n    return plot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot = plotplot(history)\nplot.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read model file from the saved model","metadata":{}},{"cell_type":"code","source":"model_file = \"/kaggle/working/model_1\" + suffix + \".h5\"\nmodel = tf.keras.models.load_model(model_file)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test on unseen data for individual characters","metadata":{}},{"cell_type":"code","source":"test_dir = \"/kaggle/input/test-basic-math/test/all/\"\nlist_img = os.listdir(test_dir)\nlist_img","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_2(img):\n    x = get_image_2(img).reshape(img_row, img_col, channel).astype(\"float32\")\n    plt.imshow(x)\n    plt.plot()\n    x = np.array([x]) / 255\n    # print(x.shape)\n    \n    pred = model.predict(x, verbose=0)[0]\n    # print(pred)\n    # print(pred.argmax())\n    print(\"Predicted label : \", label[pred.argmax()])\n    # print(label[pred.argmax()])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img in list_img:\n    print(\"img : \", img)\n    prediction_2(test_dir + img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test on equations","metadata":{}},{"cell_type":"code","source":"eq_dir = \"/kaggle/input/test-basic-math/test/eq/\"\neq_list = os.listdir(eq_dir)\neq_list","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Used to merge overlapping contours","metadata":{}},{"cell_type":"code","source":"def contour_union_2(x, y, xa, yb, key, l):\n    x_i = x[key]\n    y_i = y[key]\n    xa_i = xa[key]\n    yb_i = yb[key]\n    for j in l:\n        x_i = min(x_i, x[j])\n        y_i = min(y_i, y[j])\n        xa_i = max(xa_i, xa[j])\n        yb_i = max(yb_i, yb[j])\n    return [x_i, y_i, xa_i, yb_i]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Used to find overlapping contours and merge them into one and return them as individual contour. Use only the x-axis overlap as the equation goes from left to right.","metadata":{}},{"cell_type":"code","source":"def merge_all_contours(img, contour):\n    contours = []\n    contours_x = []\n    contours_xa = []\n    contours_y = []\n    contours_yb = []\n\n    for c in contour:\n        x,y,a,b=cv2.boundingRect(c)\n        contours.append([x, y, a, b])\n        contours_x.append(x)\n        contours_xa.append(x + a)\n        contours_y.append(y)\n        contours_yb.append(y + b)\n        # cv2.rectangle(img, (x - 5, y - 5), (x + a + 5, y + b + 5), (0, 255, 0), 2)\n    \n    overlaps={}\n\n    for i in range(len(contours)):\n        for j in range(i + 1, len(contours)):\n            if((contours_x[i] <= contours_x[j] and contours_xa[i] >= contours_x[j] and contours_xa[i] <= contours_xa[j]) or # i on left of j\n               (contours_x[i] >= contours_x[j] and contours_x[i] <= contours_xa[j] and contours_xa[i] >= contours_xa[j]) or # j on left of i\n               (contours_x[i] >= contours_x[j] and contours_xa[i] <= contours_xa[j]) or # i inside of j\n               (contours_x[i] <= contours_x[j] and contours_xa[i] >= contours_xa[j])): # j inside of i\n                if(i not in overlaps.keys()):\n                    overlaps[i] = [j]\n                else:\n                    overlaps[i].append(j)\n\n    # print(overlaps)\n\n    for key in reversed(overlaps.keys()):\n        for ival in overlaps[key]:\n            keep = []\n            if(ival not in overlaps.keys()):\n                continue\n            for jval in overlaps[ival]:\n                if(jval not in overlaps[key]):\n                    overlaps[key].append(jval)\n            overlaps[ival] = []\n    # print(overlaps)\n    \n    keys = list(overlaps.keys())\n    used_contours = []\n    max_contour = []\n    for key in keys:\n        if(len(overlaps[key]) == 0):\n            overlaps.pop(key)\n            continue\n        overlaps[key].sort()\n        used_contours.append(key)\n        used_contours.extend(overlaps[key])\n        max_contour.append(contour_union_2(contours_x, contours_y, contours_xa, contours_yb, key, overlaps[key]))\n\n    # print(overlaps)\n    # print(max_contour)\n    # print(used_contours)\n        \n    new_contour = []\n    for i in range(len(contours)):\n        if(i in used_contours):\n            continue\n        x_i = contours_x[i]\n        y_i = contours_y[i]\n        xa_i = contours_xa[i]\n        yb_i = contours_yb[i]\n        new_contour.append([x_i, y_i, xa_i, yb_i])\n\n    # print(new_contour)\n\n    new_contour.extend(max_contour)\n    new_contour.sort(key = lambda x: x[0])\n    \n    return new_contour","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Delete contours that are too small in size using individual dimension threshold and make the contour more like a square so that the resize does not ruin the image using a threshold that atleast width or height must be atleast 60% of the height or width","metadata":{}},{"cell_type":"code","source":"def adjust_contours(new_contour, dims_thresh, inc_thresh):\n    new_new_contour = []\n    for c in new_contour:\n        x,y,xa,yb=c\n        l, w = (xa-x), (yb-y)\n        contour_dims = (xa-x) * (yb-y)\n        # print(\"countour dimension: \", contour_dims)\n        if(l < dims_thresh and w < dims_thresh):\n            continue\n        add_x = 0\n        add_y = 0\n        if(l > w and w < inc_thresh * l):\n            add_y = round((inc_thresh * l - w) * inc_thresh)\n        if(w > l and l < inc_thresh * w):\n            add_x = round((inc_thresh * w - l) * inc_thresh)\n        # print(add_x, add_y)\n        if(contour_dims > dims_thresh):\n            # adding contour\n            # print(\"adding contour\")\n            \n            x = max(0, x - 5 - add_x)\n            y = max(0, y - 5 - add_y)\n            xa = min(len(img[0]), xa + 5 + add_x)\n            yb = min(len(img), yb + 5 + add_y)\n            new_new_contour.append([x,y,xa,yb])\n    return new_new_contour","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get the individual images from the whole equation photo","metadata":{}},{"cell_type":"code","source":"def get_image_all_2(file):\n    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n    img = ~img\n#     _, thresh = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n    _, thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    contour = sorted(contours, key = lambda ctr: cv2.boundingRect(ctr)[0])\n    \n    new_contour = merge_all_contours(img, contour)\n    \n    # print(\"final contours :\", new_contour)\n\n    \n    dims_thresh = 20\n    # remove small contours\n    # make contours slightly square\n    # increasing the width or length threshold\n    inc_thresh = 0.6\n    \n    final_contour = adjust_contours(new_contour, dims_thresh, inc_thresh)\n\n    # print(\"new new contour after filtering threshold:\", new_new_contour)\n\n    images = []\n\n    for c in final_contour:\n        x,y,xa,yb=c\n        cv2.rectangle(img, (x, y), (xa, yb), (0, 255, 0), 2)\n        images.append(thresh[y : yb, x : xa])\n    images = np.array(images)\n    # plt.imshow(img)\n\n    return images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preprocess image by normalizing it","metadata":{}},{"cell_type":"code","source":"def process_image(img):\n    # print(img.shape)\n    temp = cv2.resize(img, (img_row, img_col))\n    temp = temp / 255\n    temp = np.reshape(temp, (img_row, img_col, 1))\n    # return temp\n    return np.array([temp])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions:","metadata":{}},{"cell_type":"code","source":"expected = [\"5+4\", \"3+2\", \"54+3\", \"42+1\", \"21-3\", \"2*4\", \"2x+5=7\", \"y=3x+4\", \"z=3x+4y\", \"1+2\", \"4+5\", \"[4+3]*5\", \"8/2\", \"512/128\", \"52.9/68\"]\n# expected = [\"5add4\", \"3add2\", \"54add3\", \"42add1\", \"21sub3\", \"2mul4\", \"2xadd5eq7\", \"yeq3xadd4\", \"zeq3xadd4y\", \"1add2\", \"4add5\", \"[4add3]mul5\", \"8div2\", \"512div128\", \"52dec9div68\"]\n\ncount=0\nfor ind in range(len(eq_list)):\n    # og_img = cv2.imread(eq_dir + eq_list[ind], cv2.IMREAD_GRAYSCALE)\n    # plt.imshow(og_img)\n    eq_img = get_image_all_2(eq_dir + eq_list[ind])\n    eq_str = \"\"\n    for img in eq_img:\n        im = process_image(img)\n        pred = model.predict(im, verbose=0)[0]\n        lab = label[pred.argmax()]\n\n        # print(\"Predicted label : \", lab)\n        \n        if(lab == \"eq\"):\n            lab = \"=\"\n        elif(lab == \"dec\"):\n            lab = \".\"\n        elif(lab == \"add\"):\n            lab = \"+\"\n        elif(lab == \"sub\"):\n            lab = \"-\"\n        elif(lab == \"div\"):\n            lab = \"/\"\n        elif(lab == \"mul\"):\n            lab = \"*\"\n\n        eq_str += lab\n    if(expected[ind] == eq_str):\n        count += 1\n    print(expected[ind], end=\" \")\n    print(eq_str)\nprint(\"Correct predictions: \", count)\n# out of 15 images, for thresh binary\n# old/model_1_norm: 0\n# old/model_1_inv: 5\n# old/model_1_thresh: 6\n# old/model_2_norm: 0 (not correct)\n# old/model_2_inv: 1\n# old/model_2_thresh: 2\n# new/model_1_inv: 6\n# new/model_2_inv: 2\n# new/model_3_inv: 3\n\n# out of 15 images, for thresh tozero\n# old/model_1_norm: 0\n# old/model_1_inv: 5\n# old/model_1_thresh: 6\n# old/model_2_norm: 0 (not correct)\n# old/model_2_inv: 1\n# old/model_2_thresh: 2\n# new/model_1_inv: 5\n# new/model_2_inv: 3\n# new/model_3_inv: 3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}